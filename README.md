ğŸ“š RAG-Based Semantic Search System using Endee Vector Database
ğŸš€ Project Overview

This project implements a Retrieval Augmented Generation (RAG) system that enables semantic search and question answering over unstructured documents.
The core of the system is the Endee Vector Database, which stores document embeddings and performs fast similarity-based retrieval.

Instead of relying on keyword matching, the system understands the semantic meaning of user queries and retrieves the most relevant content.

ğŸ¯ Problem Statement

Traditional keyword-based search systems fail to capture semantic relationships between words and often return irrelevant results.
This project addresses that limitation by using vector embeddings and similarity search, allowing users to retrieve accurate and context-aware information from documents.

ğŸ§  Use Cases Demonstrated
1ï¸âƒ£ Semantic Search

Retrieves documents based on semantic similarity, not exact keyword matches.

Enables more accurate and flexible information retrieval.

2ï¸âƒ£ Retrieval Augmented Generation (RAG)

Relevant document chunks are retrieved from the Endee Vector Database.

The retrieved context is used to generate informed responses.

Reduces hallucination and improves answer accuracy.

ğŸ”® Future Extensions

Recommendation systems using vector similarity

Agentic AI workflows with memory and tool execution

Integration with cloud-based LLMs when API access is available

ğŸ— System Architecture
Documents
   â†“
Text Chunking
   â†“
Local Embedding Generation
   â†“
Endee Vector Database
   â†“
Semantic Similarity Search
   â†“
Context Retrieval
   â†“
Answer Generation

ğŸ“¦ Role of Endee Vector Database

Endee is used as the core vector database in this project.

It is responsible for:

Storing high-dimensional document embeddings

Performing fast cosine similarity search

Enabling semantic retrieval for RAG workflows

Persisting data using Docker volumes

Endee ensures scalable and efficient vector search, which is critical for AI-driven applications.

ğŸ›  Tech Stack

Programming Language: Python

Vector Database: Endee (Docker-based)

Embedding Model: Local transformer embeddings

Frontend: Streamlit

Containerization: Docker & Docker Compose

âš™ï¸ Setup & Installation
1ï¸âƒ£ Prerequisites

Docker Desktop (running)

Python 3.10+

At least 2 GB RAM

Port 8080 available

2ï¸âƒ£ Start Endee Server
docker compose up -d


Verify:

docker ps


Access dashboard:

http://localhost:8080

3ï¸âƒ£ Install Python Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Create Vector Index (Run Once)
python src/create_index.py


âš ï¸ Index creation is a one-time operation.
Running it again will raise a conflict error, which is expected behavior.

5ï¸âƒ£ Ingest Documents
python src/ingest.py


This step:

Splits documents into chunks

Generates embeddings

Stores vectors in Endee

6ï¸âƒ£ Run the Application
streamlit run app.py

ğŸ§ª Example Queries
What is machine learning?
Explain semantic search.
What is Retrieval Augmented Generation?
What is the role of vector databases?

ğŸ“ Project Structure
Endee-RAG-System/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ documents/
â”‚       â””â”€â”€ sample.txt
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ create_index.py
â”‚   â”œâ”€â”€ ingest.py
â”‚   â”œâ”€â”€ search.py
â”‚   â””â”€â”€ rag.py
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md

ğŸ§  Key Learnings

Vector databases are essential for semantic search and RAG pipelines

Index lifecycle management is critical in production systems

Decoupling retrieval and generation improves system reliability

Local embeddings enable offline, stable AI workflows

âœ… Conclusion

This project demonstrates a practical and scalable AI application where vector search is the core component.
By combining local embeddings with the Endee Vector Database, the system delivers accurate semantic search and RAG functionality suitable for real-world use cases.